{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wvs2/django-easy-pdf/blob/master/experimentos/Oracle/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KLEPiJQh97E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "265984eb-cb3a-416b-a7db-8f62c49db5a6"
      },
      "source": [
        "! pip install zeugma"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: zeugma in /usr/local/lib/python3.6/dist-packages (0.43)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from zeugma) (1.16.4)\n",
            "Requirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from zeugma) (3.6.0)\n",
            "Requirement already satisfied: keras>=2.1.3 in /usr/local/lib/python3.6/dist-packages (from zeugma) (2.2.4)\n",
            "Requirement already satisfied: Cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from zeugma) (0.29.10)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from zeugma) (0.21.2)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from zeugma) (0.24.2)\n",
            "Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from zeugma) (1.14.0rc1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->zeugma) (1.8.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->zeugma) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->zeugma) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.3->zeugma) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.3->zeugma) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.3->zeugma) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.3->zeugma) (1.0.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->zeugma) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.3->zeugma) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.3->zeugma) (2018.9)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (0.33.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (1.11.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (1.14.0rc0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->zeugma) (0.8.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->zeugma) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->zeugma) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->zeugma) (1.9.165)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.5.0->zeugma) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.5.0->zeugma) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.5.0->zeugma) (41.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (2019.3.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.165 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (1.12.165)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.165->boto3->smart-open>=1.2.1->gensim>=3.5.0->zeugma) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpKcx27RWIED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiwJRl23WLxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "from nltk import word_tokenize\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsOAqC5uXcTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from vector_functions import TfidfEmbeddingVectorizer, get_word2vec, MySentences, MeanEmbeddingVectorizer, MyTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncB3WEdmiGIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78b1b204-c2b3-479a-ca34-eb638e0babdf"
      },
      "source": [
        "from zeugma import EmbeddingTransformer, TextsToSequences, Padder, ItemSelector"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgTsNwZeYR8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "40f2ab52-f9f5-498f-ed54-694153e98c1c"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYGtjCs0iY94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1b9f05b9-b237-4019-a10c-fd246f132027"
      },
      "source": [
        "embedding = EmbeddingTransformer('glove-twitter-50')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAOw7mr8WlJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('tweets_union_train.csv')\n",
        "df_test = pd.read_csv('tweets_union_test.csv')\n",
        "df_val = pd.read_csv('tweets_union_val.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oK01LtIWxsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu6tbxhGWoDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_processing(tweet_text):\n",
        "    # Removendo URLS\n",
        "    new_text = re.sub(r\"http\\S+\", \"\", tweet_text)\n",
        "    # Removendo RT\n",
        "    new_text = re.sub('RT @[\\w_]+: ', '', new_text)\n",
        "    # Removendo tags\n",
        "    new_text = re.sub(r\"@\\S+\", \"\", new_text)\n",
        "    # Retirando caracteres especiais\n",
        "    new_text = normalize('NFKD', new_text).encode('ASCII', 'ignore').decode('ASCII')\n",
        "    new_text = re.sub('\\s+', ' ', new_text)\n",
        "    return new_text\n",
        "\n",
        "\n",
        "def tokenize_with_stemmer(sentence):\n",
        "    tokens = [stemmer.stem(w) for w in word_tokenize(sentence)]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72uX43XkWtn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, item in df_val.iterrows():    \n",
        "    df_train = df_train.append({'tweet': item['tweet'], 'class':item['class']}, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xqRadJkW3cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, class_train = df_train['tweet'].fillna(' ').apply(pre_processing), df_train['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggNWmJERW4of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test, class_test = df_test['tweet'].fillna(' ').apply(pre_processing), df_test['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHM5aRFCgj2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b1f99e4b-fad4-4bac-8dc2-ea26de5d5079"
      },
      "source": [
        "w2v = get_word2vec(\n",
        "    MySentences(\n",
        "        train,\n",
        "    ),\n",
        "    'w2v_model_baseline',\n",
        "    1\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w2v_model_baseline not found. training model\n",
            "Model done training. Saving to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsRcVE72g0S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWrvlRuMW7_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect_cv = CountVectorizer(analyzer='word', lowercase=True, tokenizer=tokenize_with_stemmer, stop_words='english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-MJLRTJXU1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect_tfidf = TfidfVectorizer(\n",
        "    analyzer='word', lowercase=True, tokenizer=tokenize_with_stemmer, use_idf=True, stop_words='english'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daG1zYilXYML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe_cv = Pipeline([\n",
        "    ('vect', vect_cv),\n",
        "    ('clf', SVC(kernel='linear', random_state=0))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOTGo5PcYGnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe_tfidf = Pipeline([\n",
        "    ('vect', vect_tfidf),\n",
        "    ('clf', SVC(kernel='linear', random_state=0))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy-FIATwg_H4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe_w2v = Pipeline([\n",
        "    ('vect', mean_embedding_vectorizer),\n",
        "    ('clf', SVC(kernel='linear', random_state=0))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqJG1RhQiRvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm = SVC(kernel='linear', random_state=0)\n",
        "pipe_glove = make_pipeline(embedding, svm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZXgeOv4YJBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "31530b9c-df02-403f-99a4-15e00573210e"
      },
      "source": [
        "pipe_cv.fit(train, class_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_with_stemmer at 0x7f6719359950>,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
              "                     probability=False, random_state=0, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t97bIzARYPYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "ee843d73-a329-4773-e763-d6772ec1d677"
      },
      "source": [
        "pipe_tfidf.fit(train, class_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_with_stemmer at 0x7f6719359950>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
              "                     probability=False, random_state=0, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O6p-fu7hHxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "033a95bb-300a-41f6-8a5b-dcd27cbb413a"
      },
      "source": [
        "pipe_w2v.fit(train, class_train)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 <vector_functions.MeanEmbeddingVectorizer object at 0x7f67187667b8>),\n",
              "                ('clf',\n",
              "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
              "                     probability=False, random_state=0, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EES-I5yYi3sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "10170541-96b8-414a-cf06-3e5021631848"
      },
      "source": [
        "pipe_glove.fit(train, class_train)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('embeddingtransformer',\n",
              "                 EmbeddingTransformer(aggregation='average',\n",
              "                                      model=<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f6716cb62e8>)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
              "                     probability=False, random_state=0, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry5wlDxlYY_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_cv = pipe_cv.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uhDKcqzYmUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_tfidf = pipe_tfidf.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w5tlCnChRLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_w2v = pipe_w2v.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wa9cSgjJBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_glove = pipe_glove.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4MGdds2YrRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cont_acertos(*args):\n",
        "  a, b, c, d = args\n",
        "  cont = 0\n",
        "  for k, v in class_test.items():\n",
        "    if a[k] == v or b[k] == v or c[k] == v or d[k] == v:\n",
        "      cont += 1\n",
        "  return cont"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYqH2qvqelLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "016ac323-cb6d-487c-ad58-a6dec1897ec3"
      },
      "source": [
        "print(cont_acertos(y_pred_cv, y_pred_tfidf, y_pred_w2v, y_pred_glove))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4774\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}